---
  layout: "post"
  title: "AI Adaptation"
  excerpt: "Are the standards and definitions for assessing harm tied to a small group of people?"
  image: "/assets/imgs/boat-1834397_1280.jpg"
  author: "唐鳳、江殷年"
  category: "blog"
  tags: 
    - "民主網絡"
    - "數位產業"
---


When it comes to AI governance, in addition to relevant legislation, what I want to emphasize is the "pre-deployment" AI adjustment mechanism. 

Why deploy in advance? 

For example, a few years ago, the Science and Technology News Office and I made a video, using cheap mobile phones and laptops to deepfake my own images, to tell the public how easy deepfake technology is. 

In this way, prevention and treatment can be taken early before large-scale damage occurs, and at the same time, the public can understand how to respond to risks in advance. 

The so-called AI adjustment mechanism has two directions for advance deployment: one is to quickly discover new hazards through the participation of all people; the other is how to quickly inform practitioners after discovery, and at the boundary of the hazard Set boundaries beforehand to guide developers to develop in a safe direction. 

Because AI is a general-purpose technology, it is difficult to evaluate all possible hazards during the laboratory research and development stage. Therefore, there should be a systematic approach to understand the impact on society during actual deployment through reviews at least every six months. Influence. 

But, does this mean that the standards and definitions for assessing harm are tied to a small group of people? 

Not really. We can take two approaches. The first is "voluntary reporting," which means that anyone who sees potential harm has a place where they can raise their hands to speak and discuss it with other people in similar situations. Second, we can use "random sampling" to conduct stratified sampling phone interviews after determining the population proportion. However, this traditional polling method also has its shortcomings. Usually, only multiple-choice questions can be asked, and no further open-ended questions can be asked. 

In order to respond to this challenge, we can use the "deliberative survey" model, combining deliberative discussions and random sampling, and invite hundreds or even thousands of people from across the country who are statistically representative to join video conferences in groups to brainstorm with each other. . This will allow for in-depth discussions and allow more people to participate. 

I hope that people who have not used AI at all, or have just been affected, will have the opportunity to understand this matter through the deliberation process, and think about it in their own life situations: If friends, family, or even companies start to use advanced generative AI, how will all parties respond? In this way, we can plan ahead and respond to society's needs immediately. 

