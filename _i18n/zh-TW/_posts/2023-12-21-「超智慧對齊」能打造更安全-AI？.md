---
layout: post
title: "「超智慧對齊」能打造更安全 AI？"
excerpt: "頻頻出現幻覺的 AI 系統，將不會再獲得投資人的青睞。"
image: /assets/imgs/steampunk-3169877_1280.jpg 
author: 唐鳳、江殷年
category: blog
tags:
  - 數位產業
---

近期黃仁勳預言，未來五年內，AI 會追上人類。剛回鍋的 OpenAI 執行長奧特曼也強調，AI 開發不會停。但其聯合創辦人蘇茨克維卻擔憂，次世代的 AI 可能帶來重大社會風險。他所領導的「超智慧對齊」（[Superalignment](https://openai.com/blog/introducing-superalignment)）專案，就是為此而生。	

對我來說，所謂超智慧對齊，就是「自動化對齊」，讓 AI 能持續符合人類的期待。要瞭解這個概念，我們需要先理解製作 AI 的兩個步驟，分別是預訓練與微調。

「預訓練」是取得巨量資料之後，將它壓縮成一份模型，之後在輸入要求時，就會依照原始資料的共同性，來產生答案。好比說，模型會注意到人臉的共同性，如輪廓與顏色，收到指令後，便重新畫一張人臉出來。但遇到訓練資料不足之處，就可能產生似是而非的答案，也就是所謂的「AI 幻覺」。

「微調」則是透過獎懲機制，讓模型學會人類較能接受哪些答案。舉例來說，模型應該拒絕捏造、有害的回答，給出透明、充分揭露信心水準的答案。如果訓練資料裡沒有提供相關材料，AI 也應該如實說明。

而「超智慧對齊」，指的就是運用現有的 AI 系統，來協助人類完成大部分的微調工作。

打個比方：審理複雜的專利侵權案時，法官本人未必是領域專家，但只要交由兩造的專業律師針對事件辯論，法官判斷論點是否合乎法規即可。超智慧對齊的原理，就是將人類放在類似法官的位置。

展望未來，甚至只要共筆一份「憲法式 AI」文件，就能讓 AI 自動對齊這些準則——「集體智慧計畫」與 Anthropic 已經[做出了示範](https://www.anthropic.com/index/collective-constitutional-ai-aligning-a-language-model-with-public-input)。例如以《世界人權宣言》訓練的小型 AI，就能對齊次世代的大型 AI，讓後者更接近人們期待的樣子。

作為政策制定者，我們的工作就是透過政策以及政府投資，對市場給出訊號。近期剛開幕的 AI 評測中心，就揭櫫了 AI 應該要符合的十大要點，分別是安全、彈性、準確、當責、隱私、可解釋、公平、透明、可靠、資安。如果在這十件事上背道而馳，雖然不會馬上禁用，但政府不鼓勵部署。

在 2016 年入閣之前，我曾協助蘋果 Siri 團隊六年的時間，當時團隊最注重的，就是準確、無害。我認為，隨著對齊技術的成熟，頻頻出現幻覺的 AI 系統，將不會再獲得投資人的青睞。
 
這就像 1980 年代，人類發現冰箱用的冷媒會破壞臭氧層，各國便迅速簽定了《蒙特婁議定書》，彼此約定停用期限。這對出資者就是很明確的訊號：如果再不迅速調整的話，其他競品很快就會取而代之。反之，當市場上出現更穩定、安全的 AI 供消費者使用，投資和消費就會引導業界，不至於走上歧途。
